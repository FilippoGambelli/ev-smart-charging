{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b434fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import emlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08789b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv(\"dataset/train_radiation_data.csv\")\n",
    "test  = pd.read_csv(\"dataset/test_radiation_data.csv\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset with temporal parsing and encoding\n",
    "    \"\"\"\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['minute']  = df['time'].dt.minute\n",
    "    df['weekofyr'] = df['time'].dt.isocalendar().week\n",
    "\n",
    "    # Temporal encoding using sine and cosine\n",
    "    df['hour_sin']  = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos']  = np.cos(2 * np.pi * df['hour']/24)\n",
    "    df['min_sin']   = np.sin(2 * np.pi * df['minute']/60)\n",
    "    df['min_cos']   = np.cos(2 * np.pi * df['minute']/60)\n",
    "    df['woy_sin']   = np.sin(2 * np.pi * (df['weekofyr']-1)/52)\n",
    "    df['woy_cos']   = np.cos(2 * np.pi * (df['weekofyr']-1)/52)\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "train = preprocess(train)\n",
    "test  = preprocess(test)\n",
    "\n",
    "# Features and Target\n",
    "features = [\n",
    "    'Gb(i)','Gd(i)','Gr(i)','H_sun','T2m','WS10m',\n",
    "    'hour_sin','hour_cos','min_sin','min_cos','woy_sin','woy_cos'\n",
    "]\n",
    "target = ['P']\n",
    "\n",
    "# Scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(train[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train[target])\n",
    "\n",
    "X_test_scaled  = scaler_X.transform(test[features])\n",
    "y_test_scaled  = scaler_y.transform(test[target])\n",
    "\n",
    "# Sequence generation\n",
    "LOOK_BACK = 16\n",
    "HORIZON = 16\n",
    "\n",
    "def create_sequences(X, y, look_back=LOOK_BACK, horizon=HORIZON):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back - horizon + 1):\n",
    "        Xs.append(X[i:i + look_back])\n",
    "        ys.append(y[i + look_back : i + look_back + horizon].flatten())\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_train, y_train = create_sequences(X_train_scaled, y_train_scaled)\n",
    "X_test, y_test   = create_sequences(X_test_scaled, y_test_scaled)\n",
    "\n",
    "# Flatten input for feed-forward model\n",
    "n_features = len(features)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], LOOK_BACK * n_features)\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0], LOOK_BACK * n_features)\n",
    "\n",
    "# Build Feed-Forward Model\n",
    "def build_ffnn_model(input_shape, horizon):\n",
    "    \"\"\"\n",
    "    Modello feed-forward compatibile con emlearn\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(horizon, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Create and summarize model\n",
    "model = build_ffnn_model(LOOK_BACK * n_features, HORIZON)\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_flat, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Final validation loss: {min(history.history['val_loss']):.6f}\")\n",
    "print(f\"Final validation MAE: {min(history.history['val_mae']):.6f}\")\n",
    "\n",
    "# Evaluation\n",
    "loss, mae = model.evaluate(X_test_flat, y_test)\n",
    "print(f\"\\n\\nTest Loss: {loss:.4f}, Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting model for IoT deployment...\")\n",
    "\n",
    "cmodel = emlearn.convert(model, method='inline')\n",
    "cmodel.save(file=\"../sensorPV/modelTiny.h\", name='modelTiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba00e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X min:\", scaler_X.data_min_)\n",
    "print(\"X max:\", scaler_X.data_max_)\n",
    "print(\"y min:\", scaler_y.data_min_)\n",
    "print(\"y max:\", scaler_y.data_max_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
